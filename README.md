# ğŸ“Š Data Science & Analytics Portfolio  

Welcome to my **Data Science Portfolio**! ğŸš€  
This repository brings together multiple projects where I explore **data wrangling, machine learning, and reporting**.  

---

## ğŸ“‚ Projects  

### 1ï¸âƒ£ Web Scraping â€” Medicare Portal Remark Codes  
- **Goal**: Extract **remark codes** from the Medicare portal using Python web scraping.  
- **Tech stack**: BeautifulSoup, Requests, Pandas.  
- **Notebook**: [Scraping the remark codes](Scraping%20the%20remarkCodes.ipynb)  
- **Highlights**:  
  - Automated extraction of claim remark codes.  
  - Cleaned and structured scraped data for analytics.  

---

### 2ï¸âƒ£ Iris Dataset â€” Classification  
- **Goal**: Predict flower species using ML models.  
- **Tech stack**: scikit-learn, Pandas, Seaborn, Matplotlib.  
- **Notebook**: [Iris Classification](Iris.ipynb)  
- **Highlights**:  
  - Performed EDA & visualization of Iris features.  
  - Built multiple models â†’ Random Forest achieved >95% accuracy.  

---

### 3ï¸âƒ£ California Housing Prices â€” Regression  
- **Goal**: Predict median housing prices in California using census data.  
- **Tech stack**: scikit-learn, Pandas, Matplotlib.  
- **Notebook**: [California Housing Regression](Model%20Evaluation%20-%20California%20Housing%20Prices_.ipynb)  
- **Highlights**:  
  - Data cleaning, handling missing values, feature engineering.  
  - Built regression models â†’ Random Forest performed best.  

---

## ğŸ“‘ Report  

A **comprehensive report** summarizing the findings and results is included.  
ğŸ‘‰ [Open Report](report/DataScience_Report.pdf)  

---

## ğŸ› ï¸ Tools & Libraries  

- **Languages**: Python, SQL  
- **Libraries**: Pandas, NumPy, scikit-learn, Matplotlib, Seaborn, BeautifulSoup, Requests  
- **Environments**: Jupyter Notebook, VS Code  

---

## ğŸš€ Next Steps  

- Deploy ML models using Flask / FastAPI.  
- Automate scraping with Airflow or cron jobs.  
- Add cloud-based ETL workflows (AWS, Azure, GCP).  

---

ğŸ’¡ *"I might be an anomaly but not an outlier."*  
